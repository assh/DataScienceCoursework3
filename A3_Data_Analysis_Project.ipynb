{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMP5721M: Programming for Data Science \n",
    "\n",
    "## Coursework 3: Data Analysis Project\n",
    "\n",
    "Last modified: 15 November 2023\n",
    "\n",
    "# Analysis Of Youtube Trending Data\n",
    "\n",
    "\n",
    "_Give names and emails of group members here:_\n",
    "\n",
    "* Asish Panda, mm23ap@leeds.ac.uk\n",
    "* Mohamed Imthiyas Abdul Rasheeth, mm23m2ia@leeds.ac.uk\n",
    "* Naveen Sabarinath Babu, mm23nsb@leeds.ac.uk\n",
    "* Roshan ., mm23rt@leeds.ac.uk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Requirements\n",
    "_PLEASE DELETE THIS WHOLE CELL BEFORE SUBMITTING YOUR PROJECT_\n",
    "\n",
    "The purpose of this assignment is to develop your skills\n",
    "in organising and presenting a Data Science project.\n",
    "\n",
    "Since most of the marks will be awarded for organisation\n",
    "and presentation, it is suggested that you do not initially attempt\n",
    "anything too complicated. However, once you have managed\n",
    "to get a basic pipeline working that fits the guidelines, \n",
    "you are encouraged to extend and elaborate your analysis.\n",
    "\n",
    "Your project should entirely be contained within this template file.\n",
    "You should keep the basic structure indicated below. To facilitate\n",
    "grading according to the marking scheme.\n",
    "\n",
    "You _may_ import any module that is provided with Anaconda3 Python.\n",
    "\n",
    "\n",
    "### Marking Scheme\n",
    "\n",
    "The marking scheme  is as follows:\n",
    "\n",
    "* Project Plan:\n",
    "    * Description of data to be used (10)\n",
    "    * Overview of Project Aims  (5)\n",
    "    * Design  (5)\n",
    "    \n",
    "* Program Code: (15)<br>\n",
    "    Code should be laid out in steps with explanations\n",
    "    and intermediate output with comments. \n",
    "    You should ensure that the steps do not require\n",
    "    a large amount of processing time.\n",
    "\n",
    "* Project Outcome:\n",
    "    * Explanation of Results (10)<br>\n",
    "        This should include a qualitative description\n",
    "        of the results as well as key figures and tables\n",
    "        of results.\n",
    "    * Results visualisation (10)<br>\n",
    "        This should be graphical representations of the\n",
    "        results with brief explanations (ordinary tables will be\n",
    "        graded as part of the explanation of results)\n",
    "    * Conclusion (5)\n",
    "\n",
    "### Data Resources\n",
    "\n",
    "You can use any data you like. Many useful resources are available.\n",
    "\n",
    "The Data Resources section of the module (Unit 4.3 on Minerva) has links to several example data sets.\n",
    "\n",
    "As a starting point you could browse the following:\n",
    "* [Kaggle](https://www.kaggle.com/)\n",
    "* [Our World in Data](https://ourworldindata.org/)\n",
    "* [scikit-learn datasets](https://scikit-learn.org/stable/datasets.html)\n",
    "* [scikit-learn tutorial](https://scikit-learn.org/stable/tutorial/basic/tutorial.html)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Using this Notebook Template\n",
    "Please use this notebook as a template for your project file.\n",
    "In the following cells of the notebook, _italic text_ giving explanations\n",
    "and examples should be either deleted, or, in most cases, replaced by appropriate text describing your project. \n",
    "Text that is not in italic (which is mostly headings) should\n",
    "be left as it is. __Your project report notebook should the same overall\n",
    "structure as this template notebook.__\n",
    "An exception to this is the current markup cell describing the project\n",
    "requiements. You should delete this before submitting your notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Plan\n",
    "\n",
    "## The Data (10 marks)\n",
    "\n",
    "Youtube provides an API that provides information about trendng data country-wise. The dataset on Kaggle is a real-time (daily) updating dataset derived from the API consisting of attruibutes for various contries which is used for analysis in this project. The scope of this project limits our use to a specific daterange and limited the country to Great Britain.\n",
    "\n",
    "The dataset consists of two files , _GB_category_id.json and GB_youtube_trending_data.csv_. The files contain the follwoing column ID's\n",
    "\n",
    "### CSV:\n",
    "\n",
    " ['video_id',\n",
    " 'title',\n",
    " 'publishedAt',\n",
    " 'channelId',\n",
    " 'channelTitle',\n",
    " 'categoryId',\n",
    " 'trending_date',\n",
    " 'tags',\n",
    " 'view_count',\n",
    " 'likes',\n",
    " 'dislikes',\n",
    " 'comment_count',\n",
    " 'thumbnail_link',\n",
    " 'comments_disabled',\n",
    " 'ratings_disabled',\n",
    " 'description']\n",
    "\n",
    "### JSON:\n",
    "\n",
    "The json file contains a data structure that links the categoryId column in each file. The json file alos ha sinformation about each files category i.e ['family','Entertainment','Education']. The structure of the file is as follows\n",
    "\n",
    "```\n",
    "{\n",
    "    \"kind\": \"youtube#videoCategoryListResponse\",\n",
    "    \"etag\": \"kBCr3I9kLHHU79W4Ip5196LDptI\",\n",
    "    \"items\": [\n",
    "        {\n",
    "            \"kind\": \"youtube#videoCategory\",\n",
    "            \"etag\": \"IfWa37JGcqZs-jZeAyFGkbeh6bc\",\n",
    "            \"id\": \"1\",\n",
    "            \"snippet\": {\n",
    "                \"title\": \"{{category_string}}\",\n",
    "                \"assignable\":{{boolean}},\n",
    "                \"channelId\": \"{{string}}\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"kind\": \"youtube#videoCategory\",\n",
    "            \"etag\": \"5XGylIs7zkjHh5940dsT5862m1Y\",\n",
    "            \"id\": \"2\",\n",
    "            \"snippet\": {\n",
    "                \"title\": \"{{category_string}}\",\n",
    "                \"assignable\": {{boolean}},\n",
    "                \"channelId\": \"{{string}}\"\n",
    "            }\n",
    "        },\n",
    "\t]\n",
    "}\n",
    "```\n",
    "\n",
    "## Project Aim and Objectives (5 marks)\n",
    "\n",
    "The primary objective of this project is to perform an in-depth analysis of the \"Trending Youtube API Dataset\" to identify and understand the important attributes that results in the uploaded video to be \"trending\" in the platform. The project aims to find the patterns in the dataset that would push the videos, uploaded by the users, into the trending category; thus helping the content creators to optimize their video uploads accordingly that would contribute to the Youtube Algorithm.\n",
    "\n",
    "The aim of the project is achieved by making use of data analysis techniques and machine learning algorithms to find out the correlations between the different attributes in the dataset. We will make use of columns such as {categoryId, title,view_count,likes,dislikes etc.} to recognize the patterns resulting in a trending video. After thorough analysis of the various aspects, we aim to discern the commonalities among the trending videos, while also identifying the factors that may vary across the different genres of Youtube. \n",
    "\n",
    "In summary, the project aims to provide insight into the dynamics of Youtube Trending videos, thereby helping content creators in sharing content that would satisfy the Youtube algorithm and results in the video being in the Youtube Trending. The results will help in improving the experience of the users and Youtubers on the Youtube Platform.\n",
    "\n",
    "#_Here you should describe the general aim of your project in\n",
    "around 200-300 words._\n",
    "\n",
    "#_This can can be anything from classifying items according to\n",
    "their characteristic features (which mushrooms are poisonous?) \n",
    "to simulating an evolving process (will the rabbits eat all\n",
    "the carrots or get eaten by the foxes?)_\n",
    "\n",
    "#_Here some ideas of general types of processing functionality\n",
    "that you could implement:_\n",
    "\n",
    "* _Classification: separate data items into classes according\n",
    "  to their charactersitics (can be either a definite or a\n",
    "  statistical kind of classification)_\n",
    "* _Corellation: find correspondences between different attributes within\n",
    "  a dataset_\n",
    "* _Search: find solutions matching some criteria_\n",
    "* _Visualisation: find informative ways to\n",
    "  display the structure of a large and/or complex dataset_\n",
    "* _Query Answering: create a system that enables one to retrieve information by evaluating some form of query representation_\n",
    "* _Simulation: model the evolution of a complex process_\n",
    "\n",
    "### Specific Objective(s)\n",
    "\n",
    "_You should chose and list __up to 4__ specific objectives suited to the data you will be working with and the type of project you wish to carry out. \n",
    "There should be <b>at least one\n",
    "per person doing the project</b>. There is no need\n",
    "for  the objectives them to be completely different. \n",
    "They could be different\n",
    "stages of the processing requirements, or different processing\n",
    "functions that the system  provides. Or just\n",
    "different aspects of data analysis that will be conducted.\n",
    "Typically, it is expected that there would be one objective\n",
    "per person. Replace the following examples with your own objectives:_\n",
    "\n",
    "* __Objective 1:__ _Visualize the genres that trend in the United Kingdom_\n",
    "* __Objective 2:__ _Checks the key words to be used in the Title and/or Description for a video to be in the trending category_\n",
    "* __Objective 3:__ _Calculates whether the Likes, Dislikes and View Count influences a video to trend_\n",
    "* __Objective 4:__ _Check whether the upload date and time results in a video to trend_\n",
    "\n",
    "## System Design (5 marks)\n",
    "\n",
    "_Describe your code in terms of the\n",
    "following two sections._\n",
    "\n",
    "### Architecture\n",
    "\n",
    "_Typically this would be  a pipeline in which data goes through several\n",
    "stages of transformation and analysis, but other architectures are possible.\n",
    "This does not need to be particularly complicated. A simple diagram with\n",
    "100-150 words of explanation would\n",
    "be a good way to present your architecture._\n",
    "  \n",
    "### Processing Modules and Algorithms\n",
    "\n",
    "_Briefly list and describe the most significant computational components of your system and the algorithms you will use to implement them. \n",
    "This could include things like:_\n",
    "\n",
    "* _cleaning the data by removing outliers_\n",
    "* _combining different datasets_\n",
    "* _converting samples to a special representaion (such as feature vectors)_\n",
    "* _constructing a special data-structure (such as a decision tree)_\n",
    "* _running some kind of analysis_\n",
    "\n",
    "_Your list can be presented in similar form to the one just given, \n",
    "but should include a brief\n",
    "but more specific description of the components and/or algorithms.\n",
    "Probably three or four components is sufficient for most projects, but\n",
    "you may want to have more._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program Code (15 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module Imports\n",
    "\n",
    "We are importing ```pandas``` since it is used for DataFrame operations. Along ith Pandas, we are alos using the built-in ```json``` to import our ```GB_category_id.json```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading And Combining the two files\n",
    "\n",
    "In the following code block, we read the csv and transform it into a pandas dataframe called ```dataframe_csv```. We then read the json file into a vaariable called ```categories```. We then select the category title from ```categories``` and append it into a new column in the ```dataframe_csv``` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfc= pd.read_csv('GB_youtube_trending_data.csv')\n",
    "df = pd.DataFrame(dfc)\n",
    "\n",
    "# Load the categories\n",
    "with open('GB_category_id.json') as f:\n",
    "    categories = json.load(f)\n",
    "\n",
    "# Create a dictionary to map category IDs to category names\n",
    "category_dict = {int(item['id']): item['snippet']['title'] for item in categories['items']}\n",
    "\n",
    "# Map the category IDs in the dataframe to the category names\n",
    "df['category'] = df['categoryId'].map(category_dict)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After combining both files into a single dataframe, we proceed withour initial data exploration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous code block, we take note that there are ```17``` features and ```155964``` trending videos. To ensure correct analysis we check for number of missing numbers in each column and summing it columnwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above output we can see there are ```4281``` missing descriptions and ```102``` missing categories. Since missing values in the columns won't cause problems in our analysis, we will not drop those rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicate Check\n",
    "\n",
    "We then check for duplicate rows in the dataframe using the ```duplicated()``` function of pandas. We then sum up the total to see how many rows are duplicates. From the result 124 rows are duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use ```drop_duplicates()``` function to drop those rows. We can then check the shape of the dataframe to cross verify that the duplicates were successfully deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective 1 Code Cells: _Visualize the genres that trend in the United Kingdom_ \n",
    "\n",
    "The following barplot shows us the count of the categories occuring in the dataset.\n",
    "As we can see from figure 1, Entertainment tops the list, followed by Sports, Gaming, Music and People & Blogs as Top 5 Categories across the dataset for the year between Aug 2020 to Nov 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category'].value_counts().plot.bar(title='Figure 1 - No. of Videos per Category',xlabel='Category',ylabel='Number of Trending Videos',color='royalblue')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then convert the trending_date column in the dataframe into datetime format and store it in a new column called date. Further columns are created based on year and month to aide in plotting. We can then label the month from integers to their names in english to enhance clarity. A graph is then plotted based on category and month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot bar graph based on category and date by month\n",
    "df['date'] = pd.to_datetime(df['trending_date'])\n",
    "df['month'] = df['date'].dt.month\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['month'].replace((1,2,3,4,5,6,7,8,9,10,11,12),('Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'))\n",
    "df['month'] = pd.Categorical(df['month'], categories=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'], ordered=True)\n",
    "#plot bar graph based on category and date by month\n",
    "df.groupby(['month','category']).size().unstack().plot(kind='bar',stacked=True,figsize=(18,12),title=\"Figure 2 - No. of Videos per Category by Month\",xlabel=\"Month\",ylabel='No. of Trending Videos').legend(bbox_to_anchor=(1.0, 1.0),title=\"Category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe is further filtered to the Top 5 categories as per Figure 1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot grouped bar graph for top 5 category per year\n",
    "df.groupby(['year','category']).size().groupby(level=0).nlargest(5).unstack().plot(kind='bar',stacked=False,figsize=(15,10),xlabel=\"Year\",ylabel='No. of Trending Videos',title=\"Figure 3 - Top 5 Categories per Year\").legend(bbox_to_anchor=(1.0, 1.0),title=\"Category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective 2 Code Cells:  _Checks the key words to be used in the Title and/or Description for a video to be in the trending category_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To aide in our understanding of how keywords in title affect a videos abilty to trend, we use an external python module called ```worldcloud```. This will allow us to visualize frequently mentioned words in the title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the average length of title in words\n",
    "df_test3 = df.copy()\n",
    "df_test3['title_length'] = df_test3['title'].str.split().str.len()\n",
    "df_test3['title_length'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test3['title_length'].plot.hist(bins=20,figsize=(10,5),title=\"Figure 4 - Distribution of Title Length\",xlabel=\"Title Length\",ylabel=\"Frequency\",color='royalblue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple graphs in the same cell\n",
    "fig, axes = plt.subplots(7, 2, figsize=(15, 30))\n",
    "# Add a title to the entire figure\n",
    "fig.suptitle('Figure 5 - Wordclouds for Different Categories', fontsize=20)\n",
    "\n",
    "# Get unique categories\n",
    "categories = df_test3['category'].unique()\n",
    "\n",
    "# Limit the number of categories to the number of subplots\n",
    "categories = categories[:len(axes.flatten())]\n",
    "\n",
    "# Plot the wordcloud for each category\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    category = categories[i]\n",
    "    title = df_test3[df_test3['category'] == category]['title']\n",
    "    text = ' '.join(title) \n",
    "    if text != ' ':\n",
    "        wordcloud = WordCloud(max_font_size=50, max_words=10000, background_color=\"white\").generate(text)\n",
    "        ax.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "        ax.set_title(category)\n",
    "        ax.axis(\"off\")\n",
    "        fig.suptitle('Wordcloud of Trending Video Titles by Category',fontsize=30)\n",
    "        fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test4 = df.copy()\n",
    "df_test4['tag_length'] = df_test3['tags'].str.split().str.len()\n",
    "df_test4['tag_length'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple graphs in the same cell\n",
    "fig, axes = plt.subplots(7, 2, figsize=(15, 30))\n",
    "\n",
    "# Get unique categories\n",
    "categories = df_test3['category'].unique()\n",
    "\n",
    "# Limit the number of categories to the number of subplots\n",
    "categories = categories[:len(axes.flatten())]\n",
    "\n",
    "# Plot the wordcloud for each category\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    category = categories[i]\n",
    "    tags = df_test3[df_test3['category'] == category]['tags']\n",
    "    text = ' '.join(tags)\n",
    "    if text != ' ' or text == 'None':\n",
    "        wordcloud = WordCloud(max_font_size=50, max_words=10000, background_color=\"white\").generate(text)\n",
    "        ax.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "        ax.set_title(category)\n",
    "        ax.axis(\"off\")\n",
    "        fig.suptitle('Wordcloud of Trending Video tags by Category',fontsize=30)\n",
    "        fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordcloud_gen_v2(category):\n",
    "\n",
    "    text1 = ' '.join(df_test3[df_test3['category'] == category]['title'])\n",
    "    text2 = ' '.join(df_test3[df_test3['category'] == category]['tags'])\n",
    "\n",
    "    from collections import Counter\n",
    "\n",
    "    # Generate word frequency dictionaries\n",
    "    word_freq1 = Counter(text1.split())\n",
    "    word_freq2 = Counter(text2.split())\n",
    "\n",
    "    # Find common words\n",
    "    common_words = word_freq1 & word_freq2\n",
    "\n",
    "    # Generate a word cloud using only the common words\n",
    "    common_text = ' '.join(common_words.elements())\n",
    "    if common_text != ' ' or common_text == 'None':\n",
    "        wordcloud = WordCloud(max_font_size = 50,max_words=10000, background_color=\"white\").generate(common_text)\n",
    "    return wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple graphs in the same cell\n",
    "fig, axes = plt.subplots(7, 2, figsize=(15, 30))\n",
    "\n",
    "# Get unique categories\n",
    "categories = df_test3['category'].unique()\n",
    "\n",
    "# Limit the number of categories to the number of subplots\n",
    "categories = categories[:len(axes.flatten())]\n",
    "\n",
    "# Plot the wordcloud for each category\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    category = categories[i]\n",
    "    #tags = df_test3[df_test3['category'] == category]['tags']\n",
    "    #text = ' '.join(tags)\n",
    "    \n",
    "    if text != ' ' or text == 'None':\n",
    "        ax.imshow(wordcloud_gen_v2(category), interpolation=\"bilinear\")\n",
    "        ax.set_title(category)\n",
    "        ax.axis(\"off\")\n",
    "        fig.suptitle('Wordcloud of Common Words in Trending Video Tags and Title by Category',fontsize=30)\n",
    "        fig.tight_layout(rect=[0, 0.03, 1, 0.95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective 3 Code Cells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find column names of dataframe\n",
    "df.columns\n",
    "#As you can see in the figure 3, we have taken the top five trending categories and grouped it yearwise. \n",
    "#We can see a downtrend in Entertainment from year 2021 to year 2023, while Gaming categories uprises and Music, People & Blogs and Sports have almost stayed constant.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns that are not needed - video_id, channelId, tags, channelTitle, comment_count, thumbnail_link, comments_disabled, ratings_disabled, date, month, year\n",
    "df_ob3 = df.copy()\n",
    "df_ob3 = df.drop(['video_id','channelId','tags','channelTitle','comment_count','thumbnail_link','comments_disabled','ratings_disabled','date','month','year','description'], axis=1)\n",
    "df_ob3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relation between number of likes and number of views is almost synonymous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a plot to show the relationship between the number of views and the number of likes and colour by  top 5 category\n",
    "\n",
    "#df_ob3.plot.scatter(x='view_count', y='likes', c='categoryId', figsize=(10,10))\n",
    "#df_ob3.plot.scatter(x='view_count', y='likes', figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.scatterplot(data=df_ob3, x='view_count', y='likes', hue='categoryId', palette='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relation between view count and category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ob3 = df_ob3.dropna()\n",
    "\n",
    "plt.scatter(df_ob3['view_count'],df_ob3['category'].astype(str))\n",
    "plt.xlabel('View Count')\n",
    "plt.ylabel('Category')\n",
    "plt.title('Figure 5 - Relationship between View Count and Category')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relation between likes and category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_ob3['likes'],df_ob3['category'].astype(str))\n",
    "plt.xlabel('likes')\n",
    "plt.ylabel('category')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two graphs shows almost similar results, so looking from the perspective of view_count alone avails similar results. We chose view count since the the values are generally higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ob3[df_ob3['view_count'] > df_ob3['view_count'].mean()].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ob3['title'][df_ob3['view_count'] == 0].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see 88 videos have made it to the trending dataset with 0 view count, so these can be considered as anomalies. From graphs, higher the view count -> more chances of it being recommended to users in that particular category than the ones with lower view count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ob3['title'][df_ob3['likes'] > df_ob3['likes'].mean()].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ob3['likes'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ob3.groupby('category')['likes'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ob3.groupby('category')['view_count'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new column where, if the number of likes is greater than the mean, the value is 1, otherwise 0\n",
    "\n",
    "df_ob3['likes_mean'] = (df_ob3['likes'] > df_ob3['likes'].mean()).astype(int)\n",
    "df_ob3.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(i) Relation between Likes_mean and cateogry\n",
    "(ii) Relation between 50th quantile of likes and category\n",
    "(iii) Relation between view counts mean and category\n",
    "(iv) Relation between 50th quantile of view counts and category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot graph between likes_mean and category\n",
    "df_ob3.groupby(['likes_mean','category']).size().unstack().plot(kind='bar',stacked=False,figsize=(15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ob3['likes'].quantile(0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ob3['likes'].quantile(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ob3['likes'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ob3['likes_50'] = (df_ob3['likes'] > df_ob3['likes'].quantile(.5)).astype(int)\n",
    "df_ob3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ob3.groupby(['likes_50','category']).size().unstack().plot(kind='bar',stacked=False,figsize=(15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ob3['view_count_mean'] = (df_ob3['view_count'] > df_ob3['view_count'].mean()).astype(int)\n",
    "df_ob3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ob3['view_count_50'] = (df_ob3['view_count'] > df_ob3['view_count'].quantile(.5)).astype(int)\n",
    "df_ob3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ob3['view_count_25'] = (df_ob3['view_count'] > df_ob3['view_count'].quantile(.25)).astype(int)\n",
    "df_ob3.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ob3.groupby(['view_count_mean','category']).size().unstack().plot(kind='bar',stacked=False,figsize=(15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ob3.groupby(['view_count_50','category']).size().unstack().plot(kind='bar',stacked=False,figsize=(15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ob3.groupby(['view_count_25','category']).size().unstack().plot(kind='bar',stacked=False,figsize=(15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the ratio of view_count to likes\n",
    "df_ob3['view_to_like_ratio'] = df_ob3['view_count']/df_ob3['likes']\n",
    "df_ob3['like_to_view_ratio'] = df_ob3['likes']/df_ob3['view_count']\n",
    "df_ob3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot a boxplot to show the spread of the view_to_like_ratio\n",
    "df_ob3.boxplot(column='view_to_like_ratio', figsize=(15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ob3.boxplot(column='like_to_view_ratio', figsize=(15,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shows why we neglected dislikes -> the API doesnt register dislikes after 2022 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new dataframe where videos with dislikes equal to zero is 1 and else is 0\n",
    "df_test = df.copy()\n",
    "df_test['dislikes_zero'] = df['dislikes'].apply(lambda x: 1 if x == 0 else 0)\n",
    "df_test.head()\n",
    "\n",
    "#plot line graph between dislikes_zero == 1 and date\n",
    "#df_test.groupby(['date','dislikes_zero']).size().groupby(level=0).sum().plot(kind='line',figsize=(15,10))\n",
    "\n",
    "#show that the number of dislikes reaches zero for the entire date range using plot\n",
    "df_test.groupby(['date','dislikes_zero']).size().groupby(level=0).sum().plot(kind='line',figsize=(15,10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['publishedAt'] = pd.to_datetime(df['publishedAt'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_month'] = df['publishedAt'].dt.month\n",
    "df['hour'] = df['publishedAt'].dt.hour\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "corr_list = ['hour','date','num_month','categoryId','year','likes','dislikes','comment_count','view_count']\n",
    "df[corr_list].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "fig = sns.heatmap(data = df[corr_list].corr(), annot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(2, 3, figsize=(25, 20))\n",
    "variables = ['likes', 'view_count', 'comment_count']\n",
    "x_values = ['hour','month']\n",
    "\n",
    "for i, x in enumerate(x_values):\n",
    "    for j, var in enumerate(variables):\n",
    "        sns.lineplot(x = df[x], y = df[var], data = df, ax = ax[i,j], marker = 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(2, 3, figsize=(25, 20))\n",
    "variables = ['likes', 'view_count', 'comment_count']\n",
    "x_values = ['hour','month']\n",
    "\n",
    "for i, x in enumerate(x_values):\n",
    "    for j, var in enumerate(variables):\n",
    "        sns.boxplot(x = df[x], y = df[var], data = df, ax = ax[i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(2, 3, figsize=(25, 20))\n",
    "variables = ['likes', 'view_count', 'comment_count']\n",
    "x_values = ['hour','month']\n",
    "\n",
    "for i, x in enumerate(x_values):\n",
    "    for j, var in enumerate(variables):\n",
    "        sns.boxplot(x = df[x], y = np.log(df[var]), data = df, ax = ax[i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['likes', 'view_count', 'comment_count']\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "for i, column in enumerate(columns):\n",
    "    plt.subplot(2, 4, i + 1)\n",
    "    sns.boxplot(x=np.log(df[column]))\n",
    "    plt.title(column)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tried plotting with the actual count of likes, view_count and comment_count, but the code cell couldnt be compiled. So, we went for the log of each values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['likes', 'view_count', 'comment_count']\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "for i in range(len(columns)):\n",
    "    for j in range(i+1, len(columns)):\n",
    "        plt.subplot(len(columns), len(columns), i*len(columns) + j + 1)\n",
    "        sns.scatterplot(x=np.log(df[columns[i]]), y=np.log(df[columns[j]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [\"likes\", \"dislikes\", \"comment_count\", \"categoryId\", \"year\", \"num_month\"]\n",
    "Y = [\"view_count\"]\n",
    "\n",
    "#train test split this\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[X], df[Y], test_size=0.2, random_state=42)\n",
    "\n",
    "#fit the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#predict the model\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate the model\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))\n",
    "print('Variance score: %.2f' % r2_score(y_test, y_pred))\n",
    "print('Root Mean squared error: %.2f' % mean_squared_error(y_test, y_pred, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the model\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"Actual view count\")\n",
    "plt.ylabel(\"Predicted view count\")\n",
    "plt.title(\"Actual vs Predicted view count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random forest regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# create regressor object\n",
    "regressor = RandomForestRegressor(n_estimators = 100, random_state = 201750985)\n",
    "regressor.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# predict the result\n",
    "y_pred = regressor.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))\n",
    "print('Variance score: %.2f' % r2_score(y_test, y_pred))\n",
    "print('Root Mean squared error: %.2f' % mean_squared_error(y_test, y_pred, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the model\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"Actual view count\")\n",
    "plt.ylabel(\"Predicted view count\")\n",
    "plt.title(\"Actual vs Predicted view count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Outcome (10 + 10 marks)\n",
    "\n",
    "_This section should describe the outcome of the project by means of both explanation of the results and by graphical visualisation in the form of graphs, charts or or other kinds of diagram_\n",
    "\n",
    "_The section should begin with a general overview of the results and then have a section for each of the project objectives. For each of these objectives an explanation of more specific results relating to that objective shoud be given, followed by a section presenting some visualisation of the results obtained. (In the case where\n",
    "the project had just one objective, you should still have a section describing\n",
    "the results from a general perspective followed by a section that focuses on\n",
    "the particular objective.)_\n",
    "\n",
    "_The marks for this section will be divided into 10 marks for Explanation\n",
    "and 10 marks for Visualisation. These marks will be awarded for the Project Outcome\n",
    "section as a whole, not for each objective individually. Hence, you do not\n",
    "have to pay equal attention to each. However, you are expected to have a\n",
    "some explanation and visualisation for each. It is suggested you have\n",
    "200-400 words explanation for each objective._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Overview of Results\n",
    "_Give a general overview of the results (around 200 words)._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective 1\n",
    "Visualize the Genres that trend in the United Kingdom.\n",
    "\n",
    "We take the dataset of the trending videos in the UK. We first wanted to plot a graph that gives us which category trends the most. So, in Figure 1, we can see that the Entertainment category tops the list, while Sports, Gaming, Music, People and blogs categories follow the ranking. We should also note that this is a cumulative sum of the number of videos from August 2020 to November 2023. \n",
    "\n",
    "As it has been for three years, we wanted to investigate whether this trend has remained the same for the entire dataset, month-wise. Thus, in Figure 2, we plotted a Stacked Bar plot, which gives the total number of values for each month (cumulative of years) across all the categories stacked on each other. As we can see, in October, there is a spike in the number of videos trending, followed by September and August across the years. The least number of videos trending is in February.\n",
    "\n",
    "We also can see from the plot that the top five categories in Figure 1 (in Entire Dataset) are the same top categories in Figure 2 (month-wise) as well. Thus, we further deeply investigate the top five categories (year-wise) in detail. Hence, in Figure 3, we discover that it has the highest values as expected, but we deduce two conclusions:\n",
    "1. In 2020, the number of bins in the plot is comparatively smaller than that of other bins. This is mainly because we only have the data for the last five months of 2020 (i.e., August to December 2020).\n",
    "2. We also notice a change in trend across 2021 to 2023, where the videos in the gaming category are more trending, while the Entertainment, and People and blog categories are decreasing year by year. Sports and Music categories stay in almost similar trends. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective 2\n",
    "Checks the key words to be used in the Title and/or Description for a video to be in the trending category\n",
    "\n",
    "Now, we will take a look at the keywords used in the title and how similar the keywords are among the list of trending categories in each category.\n",
    "We first created a new variable ‘title_length’ to store the number of words in each title and then plotted a histogram - Figure 4 based on number of words it has in each title. As we can see in the graph, most of the trending videos have 8 words in the title, and there are almost negligible trending videos that have over 20 words.\n",
    "\n",
    "After finding the number of words used in the title, we are now probing into finding actual keywords that are significant in the title. We use the word cloud to plot the keywords as Figure 5 for each category. As we can see in Figure 5, we can see the ones that are dark and big are more used keywords and of the highest significance. Thus, in the Entertainment category, keywords like ‘Official’, and ’Trailer’ are used more, while ‘Slow Mo’ is of lesser significance.\n",
    "\n",
    "The same goes for the rest of the categories, where ‘Official Video’ tops the list across a few categories, followed by the local keywords such as ‘Prime Minister’ for News & Politics, ‘League Highlights’ for Sports, ‘iPhone Pro’ for Science & Technology, etc.\n",
    "\n",
    "Based on the observations made, we can deduce the following key points,\n",
    "1. The audience is more intrigued to watch videos that have keywords relating to current affairs, in almost every category. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion (5 marks)\n",
    "\n",
    "_Your concluding section should be around 200-400 words. It is recommended\n",
    "that you divide it into the following sections._\n",
    "\n",
    "### Achievements\n",
    "_As we had expected, the most popular fridge magnets were of the 'meme' kind.\n",
    "We were surprised that 'smiley' fridge magnets were less common than expected.\n",
    "We conjecture that this is because, although they are apparently very popular,\n",
    "few fridges display more than one smiley. However, 'meme' based magnets can\n",
    "be found in large numbers, even on quite small fridges._\n",
    "\n",
    "### Limitations\n",
    "\n",
    "_The project was limited to a small number of fridge magents, which may not be\n",
    "typical of fridges found in the global fridge magnet ecosystem._\n",
    "\n",
    "### Future Work\n",
    "\n",
    "_In future work we would like to obtain more diverse data and study fridge magnets \n",
    "beyond the limited confines of student accomodation. We hypothesise that there\n",
    "could be a link between fridge magnet types and social class and/or educational\n",
    "achievement._"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
